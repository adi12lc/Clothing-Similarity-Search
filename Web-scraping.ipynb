{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial function to request the webpage and create a BeautifulSoup object\n",
    "# This object is used to parse and navigate the HTML of the page\n",
    "def make_soup(url):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        webpage = requests.get(url, headers=HEADERS)\n",
    "\n",
    "        # Parse the content of the request with BeautifulSoup and return the resulting object\n",
    "        return BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # In case of an error during the request, print the error and return None\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Function to extract the product title from the page\n",
    "def get_title(soup):\n",
    "    title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
    "    # If the title was found, return it stripped of leading/trailing whitespace\n",
    "    return title.text.strip() if title else \"\"\n",
    "\n",
    "# Function to extract the detail description of the product\n",
    "def get_detaildescription(soup):\n",
    "    try:\n",
    "        # Find the unordered list that contains the detail description\n",
    "        description = soup.find(\"ul\", attrs={'class':'a-unordered-list a-vertical a-spacing-mini'})\n",
    "\n",
    "        # Find all list items in the description and extract their text\n",
    "        description_items = description.find_all('span', class_='a-list-item')\n",
    "        information = [item.get_text(strip=True) for item in description_items]\n",
    "\n",
    "        # Return the details as a comma-separated string\n",
    "        return ', '.join(information)\n",
    "    except AttributeError:\n",
    "        # In case of an error while parsing, return an empty string\n",
    "        return \"\"\n",
    "\n",
    "# Function to extract the product rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        # Attempt to find the rating using the first expected class pattern\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # If the first pattern is not found, try the second pattern\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except AttributeError:\n",
    "            # If neither pattern is found, return an empty string\n",
    "            return \"\"\n",
    "    # If a rating was found, use regex to extract the numeric part and return it\n",
    "    return re.search(r'\\d+\\.\\d+', rating).group(0) if rating else \"\"\n",
    "\n",
    "# Function to extract the number of user reviews for the product\n",
    "def get_review_count(soup):\n",
    "    review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'})\n",
    "    # If the review count was found, return it stripped of leading/trailing whitespace\n",
    "    return review_count.string.strip() if review_count else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User agent and Accept-Language headers for the GET request\n",
    "HEADERS = ({'User-Agent':' ', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "# The base URL of the website to be scraped\n",
    "BASE_URL = \"https://www.amazon.in\"\n",
    "\n",
    "# The main function of the script\n",
    "def main():\n",
    "    try:\n",
    "        # The specific URL to be scraped\n",
    "        URL = \"\"\n",
    "\n",
    "        # Generate the soup object for the URL\n",
    "        soup = make_soup(URL)\n",
    "\n",
    "        # If the soup object is empty, exit the function\n",
    "        if not soup: return\n",
    "\n",
    "        # Find all anchor tags with the specified class attribute\n",
    "        links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "\n",
    "        # Create a list of the href attributes of the anchor tags\n",
    "        links_list = [link.get('href') for link in links]\n",
    "\n",
    "        # For each link, generate a dictionary of product data\n",
    "        product_data = [\n",
    "            {\n",
    "                # The title of the product\n",
    "                \"title\": get_title(make_soup(BASE_URL + link)),\n",
    "                # The detailed description of the product\n",
    "                \"detail_description\": get_detaildescription(make_soup(BASE_URL + link)),\n",
    "                # The rating of the product\n",
    "                \"rating\": get_rating(make_soup(BASE_URL + link)),\n",
    "                # The number of reviews for the product\n",
    "                \"reviews\": get_review_count(make_soup(BASE_URL + link)),\n",
    "                # The URL of the product\n",
    "                \"URL\": BASE_URL + link,\n",
    "            }\n",
    "            # This is done for each link in the links list\n",
    "            for link in links_list\n",
    "        ]\n",
    "        \n",
    "        # Convert the list of product data dictionaries into a pandas DataFrame\n",
    "        df = pd.DataFrame(product_data)\n",
    "        # Replace empty strings in the title column with NaN\n",
    "        df['title'].replace('', np.nan, inplace=True)\n",
    "        # Drop rows in the DataFrame where the title is NaN\n",
    "        df.dropna(subset=['title'], inplace=True)\n",
    "        # Write the DataFrame to a CSV file\n",
    "        df.to_csv(\"web_data.csv\", header=True, index=False)\n",
    "\n",
    "    # If an exception is thrown\n",
    "    except Exception as e:\n",
    "        # Print the error message\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# If the script is being run directly (not being imported)\n",
    "if __name__ == '__main__':\n",
    "    # Run the main function\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
